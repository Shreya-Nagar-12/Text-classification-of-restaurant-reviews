{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries \n",
    "import numpy as np   \n",
    "import pandas as pd  \n",
    "  \n",
    "# Import dataset \n",
    "dataset = pd.read_csv('C:/Users/Lenovo/Desktop/PROJECTS/Restaurant_Reviews.tsv', delimiter = '\\t') \n",
    "\n",
    "# library to clean data \n",
    "import re  #regular expression\n",
    "  \n",
    "# Natural Language Tool Kit \n",
    "\n",
    "import nltk  \n",
    "#nltk.download('stopwords') \n",
    "  \n",
    "# to remove stopword \n",
    "from nltk.corpus import stopwords #corpus means collection of text\n",
    "  \n",
    "# for Stemming propose  \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "  \n",
    "# Initialize empty array \n",
    "# to append clean text  \n",
    "corpus = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Liked\n",
      "0                           Wow... Loved this place.      1\n",
      "1                                 Crust is not good.      0\n",
      "2          Not tasty and the texture was just nasty.      0\n",
      "3  Stopped by during the late May bank holiday of...      1\n",
      "4  The selection on the menu was great and so wer...      1\n",
      "________________________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "________________________________________________________\n",
      "0                               Wow... Loved this place.\n",
      "1                                     Crust is not good.\n",
      "2              Not tasty and the texture was just nasty.\n",
      "3      Stopped by during the late May bank holiday of...\n",
      "4      The selection on the menu was great and so wer...\n",
      "                             ...                        \n",
      "995    I think food should have flavor and texture an...\n",
      "996                             Appetite instantly gone.\n",
      "997    Overall I was not impressed and would not go b...\n",
      "998    The whole experience was underwhelming, and I ...\n",
      "999    Then, as if I hadn't wasted enough of my life ...\n",
      "Name: Review, Length: 1000, dtype: object\n",
      "________________________________________________________\n",
      "0                               Wow... Loved this place.\n",
      "1                                     Crust is not good.\n",
      "2              Not tasty and the texture was just nasty.\n",
      "3      Stopped by during the late May bank holiday of...\n",
      "4      The selection on the menu was great and so wer...\n",
      "                             ...                        \n",
      "995    I think food should have flavor and texture an...\n",
      "996                             Appetite instantly gone.\n",
      "997    Overall I was not impressed and would not go b...\n",
      "998    The whole experience was underwhelming, and I ...\n",
      "999    Then, as if I hadn't wasted enough of my life ...\n",
      "Name: Review, Length: 1000, dtype: object\n",
      "________________________________________________________\n",
      "                                              Review  Liked\n",
      "0                           Wow... Loved this place.      1\n",
      "1                                 Crust is not good.      0\n",
      "2          Not tasty and the texture was just nasty.      0\n",
      "3  Stopped by during the late May bank holiday of...      1\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head())\n",
    "print(\"________________________________________________________\")\n",
    "print(type(dataset))\n",
    "print(\"________________________________________________________\")\n",
    "print(dataset.iloc[:,0]) #iloc needs index\n",
    "print(\"________________________________________________________\")\n",
    "print(dataset.loc[:,'Review']) #loc needs label\n",
    "print(\"________________________________________________________\")\n",
    "print(dataset.loc[0:3,['Review','Liked']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 (reviews) rows to clean \n",
    "for i in range(0, 1000):  #or use range(1000)\n",
    "\n",
    "    # re.sub('what to replace', 'with what', 'from which variable')\n",
    "    # ^ matches start of line; $ matches end of line\n",
    "    # column : \"Review\", row ith  \n",
    "    # [^a-zA-Z] match anything other than small n caps a-z.\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])  #removes punctuation marks(!,:?...)\n",
    "    \n",
    "    # convert all cases to lower cases \n",
    "    review = review.lower()  \n",
    "    \n",
    "    # split to array(default delimiter is \" \") \n",
    "    review = review.split()   #sentence is converted to array of words\n",
    "    \n",
    "    # creating PorterStemmer object to take main stem of each word \n",
    "    ps = PorterStemmer()  # groups inflected words n gets converted to root ex: running,ran,runs to run(root)\n",
    "    \n",
    "    # loop for stemming each word in string array at ith row     \n",
    "    review = [ps.stem(word) for word in review \n",
    "                if not word in set(stopwords.words('english'))]  \n",
    "    # stem only that word which is not part of stopword\n",
    "    # stopword are words which don't add much meaning to sentence, can be removed safely ex:the,he,have etc\n",
    "    \n",
    "    # rejoin all string array elements  to create back into a string \n",
    "    review = ' '.join(review)   \n",
    "    \n",
    "      # append each string to create  array of clean text  \n",
    "    corpus.append(review)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model \n",
    "# BOW represents corpus in vector form n that vector has no.s which represents occurance of the word in each review.\n",
    "# countvectorizer toknizes and build vocab of known words.\n",
    "# building vocab here means every column is represend with unique word and every row is review here,every row is initialized\n",
    "# with 0 then row wise vector is filled based on no. of times that word has occur in that review \n",
    "# and 0 if not occured.(written in new book 1st slot last page)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "  \n",
    "# To extract max 1500 feature. \"max_features\" is attribute to  experiment with to get better results \n",
    "cv = CountVectorizer(max_features = 1500)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wow': 1482, 'love': 777, 'place': 963, 'crust': 310, 'good': 569, 'tasti': 1297, 'textur': 1309, 'nasti': 870, 'stop': 1246, 'late': 737, 'may': 809, 'bank': 92, 'holiday': 642, 'rick': 1084, 'steve': 1239, 'recommend': 1050, 'select': 1140, 'menu': 827, 'great': 583, 'price': 997, 'get': 553, 'angri': 33, 'want': 1432, 'damn': 319, 'pho': 951, 'honeslti': 645, 'tast': 1295, 'fresh': 528, 'potato': 989, 'like': 760, 'rubber': 1098, 'could': 283, 'tell': 1302, 'made': 788, 'ahead': 15, 'time': 1331, 'kept': 720, 'warmer': 1434, 'fri': 529, 'touch': 1349, 'servic': 1149, 'prompt': 1009, 'would': 1480, 'go': 563, 'back': 83, 'cashier': 204, 'care': 196, 'ever': 447, 'say': 1125, 'still': 1241, 'end': 431, 'wayyy': 1442, 'overpr': 916, 'tri': 1359, 'cape': 192, 'cod': 245, 'ravoli': 1040, 'chicken': 222, 'cranberri': 296, 'mmmm': 847, 'disgust': 370, 'pretti': 996, 'sure': 1281, 'human': 662, 'hair': 603, 'shock': 1158, 'sign': 1169, 'indic': 684, 'cash': 202, 'highli': 635, 'waitress': 1429, 'littl': 766, 'slow': 1182, 'worth': 1479, 'let': 752, 'alon': 23, 'vega': 1403, 'burritto': 173, 'food': 514, 'amaz': 27, 'also': 24, 'cute': 317, 'less': 751, 'interior': 698, 'beauti': 108, 'perform': 943, 'right': 1086, 'red': 1051, 'velvet': 1409, 'cake': 183, 'stuff': 1259, 'never': 879, 'brought': 159, 'salad': 1109, 'ask': 59, 'hole': 641, 'wall': 1431, 'mexican': 831, 'street': 1251, 'taco': 1287, 'friendli': 532, 'staff': 1227, 'took': 1343, 'hour': 657, 'tabl': 1286, 'restaur': 1074, 'luke': 783, 'warm': 1433, 'sever': 1151, 'run': 1100, 'around': 55, 'total': 1348, 'overwhelm': 917, 'worst': 1478, 'salmon': 1110, 'sashimi': 1118, 'combo': 252, 'burger': 171, 'beer': 111, 'decent': 326, 'deal': 325, 'final': 491, 'blow': 135, 'found': 521, 'accid': 2, 'happier': 614, 'seem': 1138, 'quick': 1027, 'grab': 576, 'bite': 130, 'familiar': 473, 'pub': 1014, 'favor': 479, 'look': 772, 'elsewher': 427, 'overal': 914, 'lot': 775, 'redeem': 1052, 'qualiti': 1025, 'inexpens': 687, 'ampl': 31, 'portion': 985, 'poor': 981, 'waiter': 1428, 'feel': 481, 'stupid': 1260, 'everi': 448, 'came': 187, 'first': 497, 'visit': 1420, 'hiro': 639, 'delight': 341, 'suck': 1267, 'shrimp': 1166, 'tender': 1305, 'moist': 849, 'enough': 434, 'drag': 390, 'establish': 441, 'hard': 615, 'judg': 716, 'whether': 1456, 'side': 1168, 'gross': 593, 'melt': 824, 'styrofoam': 1262, 'eat': 410, 'sick': 1167, 'posit': 986, 'note': 893, 'server': 1148, 'attent': 66, 'provid': 1013, 'frozen': 534, 'puck': 1017, 'peopl': 939, 'behind': 113, 'regist': 1059, 'thing': 1317, 'prime': 999, 'rib': 1080, 'dessert': 352, 'section': 1136, 'bad': 85, 'gener': 551, 'beef': 110, 'cook': 275, 'sandwich': 1116, 'firehous': 496, 'greek': 586, 'dress': 395, 'pita': 961, 'hummu': 664, 'refresh': 1056, 'order': 909, 'duck': 403, 'rare': 1034, 'pink': 959, 'insid': 692, 'nice': 882, 'char': 209, 'outsid': 911, 'us': 1394, 'realiz': 1044, 'husband': 668, 'left': 746, 'sunglass': 1278, 'chow': 230, 'mein': 822, 'horribl': 651, 'attitud': 67, 'toward': 1351, 'custom': 315, 'talk': 1291, 'one': 906, 'enjoy': 433, 'huge': 661, 'wonder': 1470, 'imagin': 675, 'heart': 624, 'attack': 65, 'grill': 589, 'downtown': 389, 'absolut': 0, 'flat': 501, 'line': 763, 'excus': 457, 'much': 862, 'seafood': 1131, 'string': 1254, 'pasta': 928, 'bottom': 144, 'amount': 30, 'sauc': 1122, 'power': 992, 'scallop': 1126, 'perfectli': 942, 'rip': 1089, 'banana': 91, 'petrifi': 947, 'tasteless': 1296, 'least': 743, 'think': 1318, 'refil': 1054, 'water': 1439, 'struggl': 1257, 'wave': 1440, 'minut': 842, 'receiv': 1048, 'star': 1230, 'appet': 48, 'cocktail': 243, 'handmad': 610, 'delici': 339, 'definit': 335, 'glad': 558, 'give': 556, 'militari': 837, 'discount': 368, 'alway': 26, 'do': 375, 'gringo': 590, 'updat': 1391, 'went': 1452, 'second': 1135, 'got': 573, 'appar': 46, 'heard': 623, 'salt': 1112, 'batter': 102, 'fish': 498, 'chewi': 221, 'way': 1441, 'finish': 494, 'includ': 680, 'drink': 398, 'jeff': 706, 'beyond': 120, 'expect': 459, 'realli': 1045, 'rice': 1082, 'meh': 821, 'min': 840, 'milkshak': 839, 'noth': 894, 'chocol': 227, 'milk': 838, 'guess': 598, 'known': 729, 'excalibur': 453, 'use': 1395, 'common': 255, 'sens': 1143, 'dish': 371, 'quit': 1029, 'appal': 45, 'valu': 1400, 'well': 1451, 'sweet': 1284, 'season': 1133, 'today': 1336, 'lunch': 785, 'buffet': 166, 'cheat': 214, 'wast': 1437, 'opportun': 907, 'compani': 256, 'come': 253, 'experienc': 462, 'underwhelm': 1378, 'relationship': 1063, 'parti': 926, 'wait': 1427, 'person': 946, 'break': 152, 'walk': 1430, 'smell': 1187, 'old': 904, 'greas': 581, 'trap': 1357, 'other': 910, 'turkey': 1369, 'roast': 1091, 'bland': 132, 'everyon': 449, 'rave': 1039, 'sugari': 1271, 'disast': 366, 'tailor': 1288, 'six': 1178, 'year': 1490, 'spring': 1225, 'roll': 1093, 'oh': 902, 'yummi': 1498, 'meat': 814, 'ratio': 1038, 'unsatisfi': 1387, 'die': 355, 'everyth': 450, 'summari': 1274, 'larg': 733, 'disappoint': 364, 'dine': 358, 'experi': 461, 'sexi': 1153, 'mouth': 858, 'flirt': 506, 'hottest': 656, 'rock': 1092, 'casino': 205, 'step': 1238, 'forward': 520, 'best': 118, 'breakfast': 153, 'bye': 178, 'tip': 1333, 'ladi': 732, 'arriv': 57, 'quickli': 1028, 'cafe': 182, 'serv': 1147, 'fantast': 475, 'wife': 1461, 'garlic': 547, 'bone': 139, 'marrow': 806, 'ad': 11, 'extra': 466, 'meal': 812, 'anoth': 35, 'help': 631, 'bloddi': 133, 'mari': 803, 'town': 1352, 'cannot': 190, 'beat': 106, 'wine': 1463, 'reduct': 1053, 'better': 119, 'tigerlilli': 1330, 'afternoon': 13, 'bartend': 96, 'ambienc': 29, 'music': 867, 'play': 970, 'next': 881, 'trip': 1362, 'sooooo': 1204, 'real': 1043, 'sushi': 1283, 'lover': 778, 'honest': 646, 'yama': 1487, 'pass': 927, 'busi': 174, 'thai': 1311, 'spici': 1219, 'check': 215, 'atmospher': 62, 'kind': 726, 'mess': 829, 'steak': 1235, 'although': 25, 'sound': 1208, 'actual': 10, 'bit': 129, 'know': 728, 'manag': 798, 'eaten': 411, 'prepar': 994, 'indian': 683, 'cuisin': 313, 'boot': 141, 'worri': 1476, 'fine': 493, 'guy': 600, 'son': 1200, 'said': 1107, 'thought': 1324, 'ventur': 1411, 'away': 74, 'hit': 640, 'spot': 1223, 'night': 884, 'host': 653, 'lack': 731, 'word': 1472, 'number': 896, 'reason': 1046, 'review': 1076, 'leav': 745, 'phenomen': 949, 'ambianc': 28, 'return': 1075, 'strip': 1255, 'pork': 984, 'belli': 116, 'mediocr': 817, 'penn': 938, 'vodka': 1421, 'excel': 455, 'massiv': 808, 'meatloaf': 816, 'crispi': 305, 'wrap': 1483, 'delish': 342, 'tuna': 1368, 'rude': 1099, 'nyc': 899, 'bagel': 86, 'cream': 300, 'chees': 217, 'lox': 780, 'caper': 193, 'even': 445, 'subway': 1265, 'fact': 469, 'meet': 820, 'serious': 1145, 'solid': 1193, 'bar': 93, 'extrem': 467, 'mani': 801, 'weekend': 1447, 'empti': 430, 'suggest': 1272, 'ate': 61, 'curri': 314, 'bamboo': 90, 'shoot': 1160, 'moz': 860, 'top': 1344, 'done': 378, 'cover': 290, 'subpar': 1264, 'bathroom': 101, 'clean': 238, 'decor': 329, 'chang': 208, 'consid': 269, 'pace': 919, 'thumb': 1329, 'watch': 1438, 'pay': 931, 'ignor': 673, 'fianc': 486, 'middl': 834, 'day': 323, 'greet': 588, 'seat': 1134, 'mandalay': 799, 'bay': 103, 'forti': 519, 'five': 499, 'vain': 1398, 'crostini': 306, 'stale': 1228, 'highlight': 636, 'nigiri': 885, 'joint': 713, 'differ': 356, 'cut': 316, 'piec': 955, 'flavor': 502, 'voodoo': 1423, 'sinc': 1175, 'gluten': 562, 'free': 525, 'ago': 14, 'unfortun': 1380, 'must': 868, 'bakeri': 87, 'leftov': 747, 'reloc': 1066, 'impress': 678, 'immedi': 676, 'divers': 374, 'avoid': 72, 'cost': 280, 'full': 539, 'hand': 608, 'phoenix': 952, 'metro': 830, 'area': 52, 'treat': 1358, 'bacon': 84, 'hella': 629, 'salti': 1113, 'spinach': 1221, 'avocado': 71, 'ingredi': 690, 'sad': 1103, 'liter': 765, 'zero': 1499, 'list': 764, 'lordi': 773, 'khao': 722, 'soi': 1192, 'miss': 844, 'terrif': 1308, 'thrill': 1326, 'accommod': 3, 'vegetarian': 1406, 'daughter': 322, 'perhap': 944, 'inspir': 693, 'desir': 349, 'modern': 848, 'hip': 638, 'maintain': 794, 'cozi': 292, 'weekli': 1448, 'haunt': 619, 'sat': 1119, 'take': 1289, 'overcook': 915, 'charcoal': 210, 'decid': 327, 'send': 1142, 'verg': 1413, 'probabl': 1002, 'dirt': 361, 'someth': 1197, 'healthi': 622, 'quantiti': 1026, 'lemon': 750, 'raspberri': 1035, 'ice': 671, 'incred': 682, 'interest': 697, 'crepe': 303, 'station': 1233, 'hot': 655, 'bread': 151, 'butter': 176, 'home': 643, 'chip': 224, 'egg': 421, 'gyro': 601, 'wing': 1464, 'satisfi': 1121, 'joey': 711, 'vote': 1424, 'dog': 376, 'valley': 1399, 'reader': 1042, 'magazin': 791, 'bowl': 147, 'live': 767, 'friday': 530, 'insult': 696, 'felt': 485, 'disrespect': 373, 'drive': 400, 'exceed': 454, 'hope': 650, 'dream': 393, 'serivc': 1146, 'brunch': 161, 'invit': 699, 'last': 735, 'foot': 515, 'mix': 846, 'mushroom': 866, 'yukon': 1496, 'gold': 566, 'pure': 1021, 'white': 1457, 'corn': 277, 'beateou': 107, 'bug': 167, 'show': 1164, 'given': 557, 'climb': 239, 'kitchen': 727, 'soon': 1202, 'friend': 531, 'tartar': 1294, 'though': 1323, 'soggi': 1191, 'jamaican': 704, 'mojito': 850, 'small': 1183, 'rich': 1083, 'accordingli': 5, 'shower': 1165, 'rins': 1088, 'unless': 1384, 'mind': 841, 'nude': 895, 'see': 1137, 'lobster': 768, 'bisqu': 128, 'bussel': 175, 'sprout': 1226, 'risotto': 1090, 'filet': 488, 'need': 874, 'pepper': 940, 'cours': 287, 'none': 890, 'someon': 1196, 'either': 423, 'cold': 247, 'date': 321, 'unbeliev': 1375, 'bargain': 95, 'folk': 512, 'make': 795, 'welcom': 1450, 'special': 1215, 'main': 793, 'uninspir': 1382, 'whenev': 1455, 'world': 1475, 'annoy': 34, 'drunk': 402, 'fun': 540, 'chef': 220, 'doubl': 382, 'cheeseburg': 218, 'singl': 1176, 'patti': 930, 'apart': 42, 'pictur': 954, 'upload': 1393, 'yeah': 1489, 'coupl': 285, 'sport': 1222, 'event': 446, 'tv': 1371, 'possibl': 987, 'descript': 347, 'yum': 1497, 'eel': 417, 'yet': 1494, 'mayo': 811, 'hardest': 616, 'decis': 328, 'honestli': 647, 'suppos': 1280, 'eye': 468, 'stay': 1234, 'money': 852, 'flavour': 504, 'almost': 22, 'build': 168, 'freez': 526, 'close': 240, 'point': 977, 'ayc': 78, 'light': 757, 'dark': 320, 'set': 1150, 'mood': 855, 'base': 97, 'sub': 1263, 'par': 924, 'effort': 420, 'gratitud': 579, 'owner': 918, 'privileg': 1000, 'work': 1473, 'creami': 301, 'similar': 1171, 'complaint': 259, 'silent': 1170, 'pizza': 962, 'peanut': 935, 'fast': 478, 'godfath': 565, 'tough': 1350, 'short': 1162, 'stick': 1240, 'recal': 1047, 'charg': 211, 'tap': 1292, 'exquisit': 464, 'plu': 975, 'buck': 165, 'thu': 1328, 'far': 476, 'twice': 1372, 'self': 1141, 'proclaim': 1004, 'coffe': 246, 'wildli': 1462, 'veggitarian': 1408, 'platter': 969, 'cant': 191, 'wrong': 1485, 'madison': 790, 'ironman': 700, 'job': 710, 'dedic': 330, 'boba': 138, 'tea': 1299, 'jenni': 707, 'patio': 929, 'outstand': 912, 'goat': 564, 'skimp': 1179, 'mac': 786, 'bachi': 82, 'stink': 1242, 'burn': 172, 'saganaki': 1106, 'hate': 618, 'disagre': 363, 'fellow': 484, 'yelper': 1493, 'later': 738, 'neighborhood': 877, 'conveni': 274, 'locat': 769, 'pull': 1018, 'soooo': 1203, 'gave': 548, 'rate': 1036, 'pleas': 971, 'third': 1320, 'write': 1484, 'stir': 1243, 'noodl': 891, 'count': 284, 'box': 148, 'bore': 142, 'greedi': 585, 'corpor': 278, 'dime': 357, 'atroci': 63, 'summer': 1275, 'charm': 212, 'toast': 1335, 'english': 432, 'muffin': 863, 'untoast': 1388, 'high': 634, 'hous': 658, 'bu': 164, 'boy': 149, 'basic': 99, 'figur': 487, 'joke': 714, 'publicli': 1016, 'loudli': 776, 'bbq': 104, 'lighter': 758, 'fare': 477, 'public': 1015, 'two': 1373, 'happi': 613, 'downsid': 388, 'without': 1469, 'doubt': 383, 'except': 456, 'month': 854, 'favorit': 480, 'shawarrrrrrma': 1156, 'black': 131, 'pea': 933, 'unreal': 1386, 'vinaigrett': 1417, 'seen': 1139, 'especi': 440, 'mom': 851, 'pleasant': 972, 'honor': 648, 'hut': 669, 'coupon': 286, 'truli': 1365, 'dirti': 362, 'replenish': 1069, 'plain': 964, 'yucki': 1495, 'standard': 1229, 'omg': 905, 'delicioso': 340, 'authent': 69, 'spaghetti': 1214, 'whatsoev': 1453, 'veget': 1405, 'tucson': 1366, 'chipotl': 226, 'classi': 236, 'succul': 1266, 'basebal': 98, 'brick': 155, 'oven': 913, 'app': 44, 'multipl': 865, 'ten': 1304, 'terribl': 1307, 'equal': 439, 'pancak': 922, 'genuin': 552, 'enthusiast': 436, 'sadli': 1104, 'gordon': 572, 'ramsey': 1030, 'shall': 1154, 'sharpli': 1155, 'life': 756, 'door': 381, 'offer': 901, 'cool': 276, 'turn': 1370, 'els': 426, 'buy': 177, 'handl': 609, 'rowdi': 1097, 'find': 492, 'despic': 350, 'soup': 1210, 'lukewarm': 784, 'crave': 297, 'deserv': 348, 'stomach': 1244, 'ach': 7, 'rest': 1072, 'drop': 401, 'ball': 89, 'space': 1213, 'tini': 1332, 'elegantli': 424, 'comfort': 254, 'usual': 1396, 'eggplant': 422, 'green': 587, 'bean': 105, 'part': 925, 'inconsider': 681, 'hi': 633, 'dinner': 359, 'halibut': 605, 'told': 1338, 'happen': 612, 'car': 194, 'front': 533, 'starv': 1232, 'disgrac': 369, 'def': 333, 'ethic': 443, 'continu': 273, 'andddd': 32, 'anyon': 38, 'stuf': 1258, 'crystal': 312, 'shop': 1161, 'mall': 796, 'aria': 54, 'summar': 1273, 'nay': 871, 'transcend': 1356, 'bring': 156, 'joy': 715, 'memori': 825, 'pneumat': 976, 'condiment': 266, 'dispens': 372, 'ian': 670, 'kid': 723, 'option': 908, 'kiddo': 724, 'perfect': 941, 'famili': 472, 'impecc': 677, 'simpli': 1174, 'bouchon': 145, 'account': 6, 'screw': 1130, 'remind': 1068, 'pop': 983, 'san': 1115, 'francisco': 523, 'buldogi': 169, 'gourmet': 575, 'frustrat': 536, 'petti': 948, 'hungri': 666, 'assur': 60, 'teeth': 1301, 'sore': 1206, 'complet': 260, 'becom': 109, 'regular': 1060, 'profession': 1005, 'companion': 257, 'ground': 594, 'smear': 1186, 'track': 1353, 'everywher': 451, 'pile': 956, 'bird': 126, 'poop': 980, 'furthermor': 542, 'websit': 1444, 'mistak': 845, 'expert': 463, 'connisseur': 267, 'topic': 1345, 'jerk': 708, 'strike': 1253, 'rush': 1101, 'nicest': 883, 'across': 9, 'biscuit': 127, 'absolutley': 1, 'awkward': 76, 'lb': 742, 'cow': 291, 'th': 1310, 'gristl': 591, 'steiner': 1237, 'dollar': 377, 'anyway': 41, 'fs': 537, 'week': 1446, 'mention': 826, 'combin': 251, 'pear': 936, 'almond': 21, 'big': 121, 'winner': 1465, 'spicier': 1220, 'prefer': 993, 'ribey': 1081, 'mesquit': 828, 'anytim': 40, 'gooodd': 571, 'connoisseur': 268, 'contain': 272, 'driest': 397, 'relax': 1064, 'venu': 1412, 'group': 595, 'etc': 442, 'tater': 1298, 'tot': 1347, 'southwest': 1212, 'paid': 921, 'vanilla': 1401, 'smooth': 1189, 'profiterol': 1006, 'choux': 229, 'im': 674, 'az': 79, 'new': 880, 'carli': 197, 'due': 405, 'acknowledg': 8, 'forget': 517, 'margarita': 802, 'ventil': 1410, 'upgrad': 1392, 'letdown': 753, 'rather': 1037, 'camelback': 188, 'flower': 508, 'cartel': 200, 'trim': 1361, 'claim': 234, 'bill': 124, 'jewel': 709, 'la': 730, 'exactli': 452, 'nearli': 872, 'limit': 762, 'crab': 294, 'leg': 748, 'toro': 1346, 'thinli': 1319, 'slice': 1181, 'wagyu': 1426, 'truffl': 1364, 'dont': 379, 'long': 770, 'attach': 64, 'ga': 544, 'awesom': 75, 'wors': 1477, 'humili': 663, 'worker': 1474, 'bunch': 170, 'call': 185, 'conclus': 265, 'fill': 489, 'daili': 318, 'tragedi': 1355, 'struck': 1256, 'crawfish': 298, 'monster': 853, 'funni': 541, 'multi': 864, 'grain': 577, 'pumpkin': 1019, 'pecan': 937, 'fluffi': 509, 'airlin': 16, 'noca': 888, 'lettuc': 754, 'thoroughli': 1322, 'homemad': 644, 'thin': 1316, 'cheesecurd': 219, 'typic': 1374, 'glanc': 559, 'item': 702, 'gone': 568, 'greasi': 582, 'unhealthi': 1381, 'might': 835, 'similarli': 1172, 'deliveri': 344, 'man': 797, 'apolog': 43, 'expens': 460, 'pack': 920, 'tiramisu': 1334, 'cannoli': 189, 'sun': 1276, 'whole': 1458, 'choos': 228, 'frenchman': 527, 'martini': 807, 'entre': 438, 'gc': 549, 'sampl': 1114, 'thirti': 1321, 'vacant': 1397, 'yellowtail': 1492, 'carpaccio': 198, 'stranger': 1249, 'hello': 630, 'strang': 1248, 'boyfriend': 150, 'recent': 1049, 'donut': 380, 'save': 1124, 'room': 1094, 'mayb': 810, 'howev': 659, 'suffer': 1269, 'tapa': 1293, 'vinegrett': 1418, 'babi': 81, 'believ': 114, 'hanker': 611, 'forth': 518, 'theft': 1314, 'eew': 418, 'wit': 1468, 'guest': 599, 'regularli': 1061, 'super': 1279, 'swung': 1285, 'deepli': 332, 'effici': 419, 'fan': 474, 'sucker': 1268, 'dri': 396, 'cheap': 213, 'perpar': 945, 'present': 995, 'giant': 554, 'lightli': 759, 'dust': 407, 'powder': 991, 'sugar': 1270, 'fo': 510, 'accomod': 4, 'vegan': 1404, 'veggi': 1407, 'crumbi': 309, 'color': 250, 'instead': 695, 'crouton': 307, 'crema': 302, 'caf': 181, 'expand': 458, 'wish': 1467, 'philadelphia': 950, 'sit': 1177, 'fairli': 471, 'crisp': 304, 'north': 892, 'scottsdal': 1128, 'soooooo': 1205, 'freak': 524, 'paper': 923, 'reheat': 1062, 'ok': 903, 'wedg': 1445, 'sorri': 1207, 'tongu': 1341, 'cheek': 216, 'bloodi': 134, 'despit': 351, 'yellow': 1491, 'saffron': 1105, 'thru': 1327, 'mean': 813, 'half': 604, 'somehow': 1195, 'luck': 782, 'non': 889, 'focus': 511, 'grandmoth': 578, 'hostess': 654, 'four': 522, 'blue': 137, 'shirt': 1157, 'vibe': 1416, 'drastic': 391, 'caesar': 180, 'promptli': 1010, 'madhous': 789, 'proven': 1012, 'dead': 324, 'greatest': 584, 'macaron': 787, 'insan': 691, 'inform': 689, 'somewhat': 1199, 'edibl': 414, 'promis': 1008, 'fail': 470, 'deliv': 343, 'averag': 70, 'plater': 968, 'togeth': 1337, 'poorli': 982, 'construct': 271, 'italian': 701, 'scream': 1129, 'legit': 749, 'book': 140, 'somethat': 1198, 'duo': 406, 'violinist': 1419, 'song': 1201, 'request': 1070, 'baklava': 88, 'baba': 80, 'ganoush': 545, 'mgm': 832, 'courteou': 289, 'eclect': 412, 'ring': 1087, 'nobu': 887, 'googl': 570, 'smashburg': 1185, 'gem': 550, 'plantain': 965, 'spend': 1217, 'cotta': 282, 'slaw': 1180, 'drench': 394, 'piano': 953, 'soundtrack': 1209, 'rge': 1078, 'fillet': 490, 'relleno': 1065, 'plate': 967, 'sergeant': 1144, 'auju': 68, 'hawaiian': 620, 'breez': 154, 'mango': 800, 'magic': 792, 'pineappl': 958, 'smoothi': 1190, 'mortifi': 856, 'needless': 875, 'drip': 399, 'mostli': 857, 'hospit': 652, 'industri': 686, 'refrain': 1055, 'cibo': 232, 'longer': 771, 'read': 1041, 'pro': 1001, 'simpl': 1173, 'dough': 385, 'tonight': 1342, 'elk': 425, 'hook': 649, 'classic': 237, 'quaint': 1023, 'compliment': 261, 'thank': 1312, 'dylan': 408, 'tummi': 1367, 'gratuiti': 580, 'larger': 734, 'fli': 505, 'appl': 50, 'juic': 717, 'han': 607, 'bare': 94, 'ryan': 1102, 'edinburgh': 415, 'revisit': 1077, 'chines': 223, 'pine': 957, 'nut': 897, 'airport': 17, 'speedi': 1216, 'calligraphi': 186, 'anyth': 39, 'complain': 258, 'stood': 1245, 'begin': 112, 'awkwardli': 77, 'extens': 465, 'wide': 1459, 'array': 56, 'inflat': 688, 'smaller': 1184, 'grow': 596, 'rapidli': 1033, 'lil': 761, 'fuzzi': 543, 'wonton': 1471, 'thick': 1315, 'level': 755, 'spice': 1218, 'whelm': 1454, 'crowd': 308, 'mid': 833, 'arepa': 53, 'jalapeno': 703, 'that': 1313, 'shoe': 1159, 'leather': 744, 'defin': 334, 'low': 779, 'key': 721, 'afford': 12, 'sour': 1211, 'sunday': 1277, 'tradit': 1354, 'hunan': 665, 'style': 1261, 'bother': 143, 'flair': 500, 'nutshel': 898, 'restaraunt': 1073, 'market': 805, 'sewer': 1152, 'girlfriend': 555, 'veal': 1402, 'satifi': 1120, 'join': 712, 'club': 241, 'via': 1415, 'email': 428, 'case': 201, 'colder': 248, 'flavorless': 503, 'describ': 346, 'tepid': 1306, 'chain': 207, 'easili': 409, 'nacho': 869, 'crazi': 299, 'juri': 718, 'lawyer': 741, 'court': 288, 'wienerschnitzel': 1460, 'idea': 672, 'brother': 158, 'law': 740, 'herea': 632, 'tribut': 1360, 'held': 627, 'salsa': 1111, 'pissd': 960, 'surpris': 1282, 'golden': 567, 'fell': 482, 'bruschetta': 162, 'devin': 354, 'employe': 429, 'lastli': 736, 'mozzarella': 861, 'neglig': 876, 'unwelcom': 1389, 'consist': 270, 'fruit': 535, 'peach': 934, 'blown': 136, 'put': 1022, 'plastic': 966, 'cram': 295, 'takeout': 1290, 'cr': 293, 'pe': 932, 'delic': 338, 'aw': 73, 'kabuki': 719, 'maria': 804, 'articl': 58, 'fuck': 538, 'caballero': 179, 'head': 621, 'round': 1096, 'disbelief': 367, 'qualifi': 1024, 'version': 1414, 'toler': 1339, 'polit': 979, 'wash': 1436, 'heat': 625, 'coconut': 244, 'fella': 483, 'huevo': 660, 'ranchero': 1032, 'appeal': 47, 'pricey': 998, 'temp': 1303, 'glove': 561, 'deep': 331, 'pleasur': 973, 'plethora': 974, 'seal': 1132, 'approv': 51, 'colleg': 249, 'class': 235, 'start': 1231, 'edit': 416, 'besid': 117, 'costco': 281, 'uniqu': 1383, 'weird': 1449, 'hardli': 617, 'groceri': 592, 'store': 1247, 'japanes': 705, 'dude': 404, 'doughi': 386, 'inch': 679, 'wire': 1466, 'albondiga': 19, 'tomato': 1340, 'meatbal': 815, 'three': 1325, 'medium': 819, 'refus': 1058, 'anymor': 37, 'killer': 725, 'latt': 739, 'allergi': 20, 'warn': 1435, 'clue': 242, 'mediterranean': 818, 'rotat': 1095, 'concern': 264, 'mellow': 823, 'strawberri': 1250, 'unprofession': 1385, 'loyal': 781, 'bellagio': 115, 'anticip': 36, 'weak': 1443, 'correct': 279, 'bought': 146, 'sal': 1108, 'unexperienc': 1379, 'steakhous': 1236, 'properli': 1011, 'understand': 1377, 'concept': 263, 'guacamol': 597, 'pur': 1020, 'ed': 413, 'postino': 988, 'poison': 978, 'batch': 100, 'yay': 1488, 'hilari': 637, 'christma': 231, 'eve': 444, 'rememb': 1067, 'biggest': 123, 'entir': 437, 'teamwork': 1300, 'degre': 336, 'ri': 1079, 'calamari': 184, 'fondu': 513, 'lost': 774, 'forev': 516, 'scene': 1127, 'denni': 345, 'downright': 387, 'waaaaaayyyyyyyyyi': 1425, 'sangria': 1117, 'glass': 560, 'ridicul': 1085, 'brisket': 157, 'neat': 873, 'trippi': 1363, 'hurri': 667, 'reserv': 1071, 'stretch': 1252, 'cashew': 203, 'undercook': 1376, 'chipolt': 225, 'ranch': 1031, 'dip': 360, 'saus': 1123, 'douchey': 384, 'indoor': 685, 'garden': 546, 'con': 262, 'spotti': 1224, 'neither': 878, 'ensu': 435, 'bing': 125, 'carb': 195, 'profound': 1007, 'deuchebaggeri': 353, 'smoke': 1188, 'solidifi': 1194, 'ala': 18, 'cart': 199, 'del': 337, 'hamburg': 606, 'hell': 628, 'gotten': 574, 'ya': 1486, 'shot': 1163, 'firebal': 495, 'disapppoint': 365, 'heimer': 626, 'vomit': 1422, 'circumst': 233, 'brownish': 160, 'obvious': 900, 'movi': 859, 'ha': 602, 'flop': 507, 'problem': 1003, 'bigger': 122, 'unwrap': 1390, 'mile': 836, 'brushfir': 163, 'mirag': 843, 'refri': 1057, 'crusti': 311, 'caterpillar': 206, 'appetit': 49, 'instantli': 694, 'ninja': 886, 'pour': 990, 'wound': 1481, 'draw': 392}\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# X contains corpus (dependent variable) \n",
    "X = cv.fit_transform(corpus).toarray()  \n",
    "#print(cv.vocabulary_)\n",
    "#print(X)\n",
    "# y contains answers if review  is positive or negative \n",
    "y = dataset.iloc[:, 1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words are removed as they dont provide uniqe info and occur in abundance, if not removed longer vector will be formed\n",
    "# stemming is done to reduce size of vector, this will induce to root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# experiment with \"test_size\"  to get better results \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[75 59]\n",
      " [18 98]]\n",
      "\n",
      "\n",
      "Accuracy is  69.2 %\n",
      "Precision is  0.62\n",
      "Recall is  0.84\n"
     ]
    }
   ],
   "source": [
    "# NB\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",cm)\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = precision_score(y_test,y_pred)\n",
    "score3= recall_score(y_test,y_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy is \",round(score1*100,2),\"%\")\n",
    "print(\"Precision is \",round(score2,2))\n",
    "print(\"Recall is \",round(score3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[106  28]\n",
      " [ 31  85]]\n",
      "\n",
      "\n",
      "Accuracy is  76.4 %\n",
      "Precision is  0.75\n",
      "Recall is  0.73\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn import linear_model\n",
    "classifier = linear_model.LogisticRegression(C=1.5)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",cm)\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = precision_score(y_test,y_pred)\n",
    "score3= recall_score(y_test,y_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy is \",round(score1*100,2),\"%\")\n",
    "print(\"Precision is \",round(score2,2))\n",
    "print(\"Recall is \",round(score3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
